{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from config import (consumer_key, \n",
    "                    consumer_secret, \n",
    "                    access_token, \n",
    "                    access_token_secret)\n",
    "import os\n",
    "# Import and Initialize Sentiment Analyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import ast\n",
    "from time import sleep\n",
    "\n",
    "# Twitter API Keys\n",
    "consumer_key = consumer_key\n",
    "consumer_secret = consumer_secret\n",
    "access_token = access_token\n",
    "access_token_secret = access_token_secret\n",
    "\n",
    "# Twitter credentials\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wtf does this do?\n",
    "def rwCSV(path,rw='r',df=None,columns=None):\n",
    "    '''\n",
    "    Reads CSV from path to pandas dataframe (rw='r')\n",
    "    Writes/appends to CSV path from pandas dataframe (rw='w')\n",
    "    Columns: array-like\n",
    "    '''\n",
    "    if rw=='r':\n",
    "        if os.path.isfile(path): \n",
    "            print('rwCSV: returning DF from CSV')\n",
    "            return pd.read_csv(path)\n",
    "        else: \n",
    "            print(f'rwCSV: returning new DF with columns: {columns}')\n",
    "            return pd.DataFrame(columns=columns)\n",
    "    elif rw=='w':\n",
    "        df = pd.DataFrame(df)\n",
    "        # if file does not exist write with header \n",
    "        if not os.path.isfile(path):\n",
    "            df.to_csv(path,index=False, columns=columns)\n",
    "            print(f\"rwCSV: saved {df.shape[0]} row(s) as new file to '{path}'\")\n",
    "        else: # else it exists so append without writing the header\n",
    "            df.to_csv(path,mode = 'a',header=False,index=False, columns=columns)\n",
    "            print(f\"rwCSV: appended {df.shape[0]} row(s) to '{path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#srsly\n",
    "def getMentions():\n",
    "    '''\n",
    "    gets mentions from twitter and saves to CSV file\n",
    "    '''\n",
    "    #set up resulting columns\n",
    "    columns = ['mention_tweet_id','text','mentioned_users','mention_date', \\\n",
    "               'mention_user_id','mention_user_name','full_response']\n",
    "\n",
    "    #set up my twitter account number\n",
    "    my_id = api.me()['id']\n",
    "\n",
    "    #get mentions\n",
    "    try:\n",
    "        mention_response = api.mentions_timeline()\n",
    "        #print('got some kind of response')\n",
    "    except tweepy.TweepError as e:\n",
    "        print(f\"getMentions: Something's not right. Error: {e}\")\n",
    "        mention_response = False\n",
    "\n",
    "    #if there are mentions go on\n",
    "    if mention_response:\n",
    "        print(f'getMentions: Got response with {len(mention_response)} tweet(s)')\n",
    "\n",
    "        # try reading mentions CSV\n",
    "        path = 'results/mentions.csv'\n",
    "        mentions_df = rwCSV(path,columns=columns)\n",
    "        new_mentions_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "        #add mentions to a DF\n",
    "        for response in mention_response:\n",
    "            #set up mentioned list\n",
    "            mentioned_list = []\n",
    "\n",
    "            #create list of mentioned users\n",
    "            for mention in response['entities']['user_mentions']:\n",
    "                if mention['id'] != my_id:\n",
    "                    print(f\"getMentions: adding mention id: {mention['id']}\")\n",
    "                    mentioned_list.append(mention['id'])\n",
    "\n",
    "            #check if the tweet has already been added to DF\n",
    "            #and that there are in fact mentioned users in the tweet\n",
    "            if response['id'] not in mentions_df['mention_tweet_id'].tolist() and \\\n",
    "                len(mentioned_list) > 0:\n",
    "                mentions_dict = {'mention_tweet_id':response['id'],\n",
    "                                 'text':response['text'],\n",
    "                                 'mentioned_users':mentioned_list,\n",
    "                                 'mention_date':response['created_at'],\n",
    "                                 'mention_user_id':response['user']['id'],\n",
    "                                 'mention_user_name':response['user']['name'],\n",
    "                                 'full_response':response \\\n",
    "                                }\n",
    "                #grab all the mentions (append to CSV)\n",
    "                mentions_df = mentions_df.append(mentions_dict,ignore_index=True)\n",
    "                \n",
    "                #grab only new mentions (append to empty DF)\n",
    "                new_mentions_df = new_mentions_df.append(mentions_dict,ignore_index=True)\n",
    "                #convert dates\n",
    "                mentions_df['mention_date'] = pd.to_datetime(mentions_df['mention_date'])\n",
    "                new_mentions_df['mention_date'] = pd.to_datetime(mentions_df['mention_date'])\n",
    "            else:\n",
    "                print(f\"getMentions: Tweet id: {response['id']} is in CSV already or doesn't have a valid mentioned user\")\n",
    "        #save to CSV\n",
    "        if new_mentions_df.shape[0] > 0:\n",
    "            print(f'getMentions: saving new mentions to CSV')\n",
    "            rwCSV(path,'w',new_mentions_df,columns)\n",
    "        else:\n",
    "            print('getMentions: No new mentions')\n",
    "\n",
    "    #if getMentions() responded with False\n",
    "    else: \n",
    "        print('getMentions: No new mentions')\n",
    "    return mentions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentiment(id,pages=1):\n",
    "    '''\n",
    "    Returns 'pages'*100 compound sentiment analysis for twitter user 'id'\n",
    "    '''\n",
    "    mentioned_user = id\n",
    "    \n",
    "    if pages > 5: pages = 5\n",
    "    else: pages = pages\n",
    "        \n",
    "    count = 100\n",
    "\n",
    "    sentiment_df = pd.DataFrame()\n",
    "    \n",
    "    #setup list for tweets\n",
    "    tweets_of_mentioned_user = []\n",
    "\n",
    "    #get and analyse tweets\n",
    "    for page in range(1,pages+1):\n",
    "\n",
    "        #get 100 tweets at once\n",
    "        print(f'getSentiment: trying to obtain tweets for user id {mentioned_user}, page {page}')\n",
    "        try:\n",
    "            public_tweets = api.user_timeline(id=mentioned_user,count=count,page=page)\n",
    "        except:\n",
    "            public_tweets = False\n",
    "\n",
    "        #loop through obtained tweets\n",
    "        if public_tweets:\n",
    "            for tweet in public_tweets:\n",
    "                result = analyzer.polarity_scores(tweet[\"text\"])\n",
    "\n",
    "                sentiment_dict = {\n",
    "                    'user_id':mentioned_user,\n",
    "                    'date':tweet['created_at'],\n",
    "                    'tweet':tweet[\"text\"],\n",
    "                    'compound':result['compound'],\n",
    "                    'positive':result['pos'],\n",
    "                    'neutral':result['neu'],\n",
    "                    'negative':result['neg']\n",
    "                }\n",
    "\n",
    "                #grab all the mentions\n",
    "                sentiment_df = sentiment_df.append(sentiment_dict,ignore_index=True)\n",
    "\n",
    "    return sentiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeGraph(df,mentioned_user):\n",
    "    path = 'results/image_' + str(mentioned_user) + '.png'\n",
    "    mentioned_user_name = api.get_user(mentioned_user)['screen_name']\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    f, ax = plt.subplots(figsize=(20,10))\n",
    "    df.plot(marker=\"o\",markersize=10,linewidth=0.5, alpha=0.8)\n",
    "    plt.gca().invert_xaxis()\n",
    "    plt.xlim([len(df.index),0])\n",
    "    plt.ylabel(\"Tweet polarity \\n<negative.........positive>\")\n",
    "    plt.xlabel(\"Tweets Ago\")\n",
    "    now = datetime.now()\n",
    "    now = now.strftime(\"%m/%d/%Y\")\n",
    "    plt.title(f\"Sentiment analysis of @{mentioned_user_name} tweets as of {now}\")\n",
    "    plt.savefig(path, format='png')\n",
    "    #plt.show()\n",
    "    plt.close()\n",
    "    api.update_with_media(path)\n",
    "    return mentioned_user_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker():\n",
    "    #get new mentions as DF\n",
    "    mentions_df = getMentions()\n",
    "\n",
    "    #setup resulting CSV\n",
    "    path_to_analyzed = 'results/analyzed.csv'\n",
    "    path_to_sentiment = 'results/sentiment.csv'\n",
    "    columns_analyzed = ['user_id','user_name']\n",
    "    columns_sentiment = ['user_id','date','tweet','compound','positive','negative','neutral']\n",
    "    print('worker: trying to read analyzed CSV')\n",
    "    analyzed_df = rwCSV(path_to_analyzed,columns=columns_analyzed)\n",
    "\n",
    "    #got through not analyzed rows\n",
    "    for index, row in mentions_df.iterrows():\n",
    "        #get the list of mentioned users\n",
    "        #Note. for some reason `row` returns a string type variable and not list\n",
    "        #therefore using ast.literal_eval function to convert it to list\n",
    "        \n",
    "        if row['mentioned_users']:\n",
    "            mentioned_users = ast.literal_eval(str(row['mentioned_users']))\n",
    "            #loop through the list to analyse tweets and post graphs\n",
    "            for mentioned_user in mentioned_users:\n",
    "                if mentioned_user not in analyzed_df['user_id'].tolist():\n",
    "                    print(f'worker: performing sentiment analysis for user_id {mentioned_user}')\n",
    "                    sentiment = getSentiment(mentioned_user,pages=5)\n",
    "                    rwCSV(path_to_sentiment,'w',df=sentiment,columns = columns_sentiment)\n",
    "\n",
    "                    print(f'worker: performed sentiment analysis for user_id {mentioned_user}')\n",
    "                    mentioned_user_name = makeGraph(sentiment['compound'],mentioned_user)\n",
    "                    print(f'worker: generated and tweeted graph for @{mentioned_user_name}')\n",
    "\n",
    "                    #change flag to analyzed and save CSV\n",
    "                    analyzed_df = analyzed_df.append({'user_name':mentioned_user_name,\n",
    "                                                      'user_id':mentioned_user\n",
    "                                                      },ignore_index=True)\n",
    "                    rwCSV(path_to_analyzed,'w',analyzed_df,columns)\n",
    "                else:\n",
    "                    print(f'worker: user id: {mentioned_user} has already been analyzed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing worker:\n",
      "getMentions: Something's not right. Error: [{'message': 'Rate limit exceeded', 'code': 88}]\n",
      "getMentions: No new mentions\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'mentions_df' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-22f629434b7b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Initializing worker:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mworker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-5241dc0fec28>\u001b[0m in \u001b[0;36mworker\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mworker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m#get new mentions as DF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mmentions_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetMentions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m#setup resulting CSV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-42cdfb053248>\u001b[0m in \u001b[0;36mgetMentions\u001b[1;34m()\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'getMentions: No new mentions'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmentions_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'mentions_df' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# run the program\n",
    "if __name__ == '__main__':\n",
    "    while True:\n",
    "        print('Initializing worker:')\n",
    "        worker()\n",
    "        sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.me()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
